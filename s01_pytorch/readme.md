# PyTorch study topics
## Tensor Basics
- Create tensors of different data types. 
- Perform basic tensor operations (addition, subtraction, multiplication, etc.). 
- Reshape tensors using .view() or .reshape().
 
## Tensor Indexing and Slicing
- Extract specific elements, rows, or columns from tensors. 
- Modify specific elements within tensors. 

## Tensor Broadcasting
- Understand and apply broadcasting rules in tensor operations. 

## Math Operations
- Implement mathematical functions (e.g., torch.exp(), torch.log(), torch.sin(), etc.). 
- Calculate means, sums, and other statistics.

## Autograd and Gradients
- Define tensors with the requires_grad attribute. 
- Perform backpropagation to compute gradients. 
- Use the optimizer (e.g., SGD) for automatic gradient updates. 

## Neural Networks
- Create a simple feedforward neural network using nn.Module. 
- Define custom loss functions. 
- Train a neural network on a dataset using DataLoader. 

## Convolutional Neural Networks (CNNs)
- Define and train a CNN for image classification. 
- Visualize and interpret convolutional layers. 

## Recurrent Neural Networks (RNNs)
- Build and train a basic RNN or LSTM for sequence data.

## Transfer Learning
- Fine-tune a pre-trained model (e.g., ResNet, VGG) on a new dataset. 

## Data Augmentation
- Apply data augmentation techniques to improve model generalization. 

## Save and Load Models
- Save and load model weights and architectures. 

## Hyperparameter Tuning
- Use libraries like PyTorch Lightning or Optuna for hyperparameter optimization. 

## GPU Acceleration
- Utilize GPU acceleration for training deep learning models. 

## Data Handling
- Preprocess and load data using DataLoader and torchvision transforms. 

## Evaluation and Metrics
- Calculate evaluation metrics (accuracy, precision, recall, F1-score, etc.) for classification tasks. 

## Visualizations
- Visualize model outputs, gradients, and filters using libraries like Matplotlib. 

## Custom Layers and Losses
- Create custom layers and loss functions by subclassing PyTorch classes. 

## Deployment
- Export a trained model for deployment (e.g., ONNX, TorchScript). 

## Parallelism and Distributed Training
- Train models on multiple GPUs or in a distributed environment. 

## Natural Language Processing (NLP)
- Tokenize text data, build embeddings, and create an NLP model (e.g., using Transformers).

# Pytorch Resources
* Books
    * Deep Learning with Pytorch - Eli Stevens
    * [Deep Learning for Coders with Fastai and Pytorch - Jeremy Howard](https://nbviewer.org/github/fastai/fastbook/tree/master/)

* Courses
    * [Fast AI Course](https://course.fast.ai)
    * [U. Amsterdam Course](https://uvadlc.github.io)

* Lectures
    * [Andrej Karpathy Youtube](https://www.youtube.com/@AndrejKarpathy/videos)